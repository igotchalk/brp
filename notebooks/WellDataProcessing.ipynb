{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import lasio\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import glob\n",
    "from scipy.stats import mode\n",
    "import warnings\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = Path('../')\n",
    "lasdir = workdir.joinpath('data','las_MPWSP')\n",
    "# lasdir = workdir.joinpath('data','las_all')\n",
    "\n",
    "auxdir=  workdir.joinpath('data','auxiliary')\n",
    "figdir=  workdir.joinpath('work','figs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myround(x, base=.5):\n",
    "    return base*np.round(x/base)\n",
    "def mask_nonan(df,nan_col_list):\n",
    "    mask = df.notnull()\n",
    "    return mask.loc[:,nan_col_list].all(axis=1)\n",
    "\n",
    "def mask_noclay(df,nan_col_list):\n",
    "    return ~df.loc[mask_nonan(df,nan_col_list),'lith'].str.contains(\"C\")\n",
    "\n",
    "def mask_SP_only(df,nan_col_list):\n",
    "    return df.loc[mask_nonan(df,nan_col_list),'lith']==\"SP\"\n",
    "\n",
    "def mask_stds(df,nstds,testcol,nan_col_list):\n",
    "    pop = df.loc[mask_nonan(df,nan_col_list),testcol]\n",
    "    return  np.logical_and(pop < np.mean(pop)+nstds*np.std(pop),\n",
    "                           pop > np.mean(pop)-nstds*np.std(pop))\n",
    "def mask_wherescreen(df,nan_col_list):\n",
    "    return  mask_nonan(df[df.screen.notnull()],nan_cols)\n",
    "\n",
    "def tds2rho_est(tds,m=.692826,b=-220.28):\n",
    "    return 1e4*m/(tds-b)\n",
    "\n",
    "def rho2tds_est(rho,m=.692826,b=-220.28):\n",
    "    return 1e4*m/rho + b\n",
    "\n",
    "def cond2rho(cond):\n",
    "    return 1e4/cond\n",
    "    \n",
    "def nested_logicals(df,list_of_conditions,func=np.logical_and):\n",
    "    '''\n",
    "    Convenience function to nest numpy logical functions\n",
    "        Input: \n",
    "            df\n",
    "            list_of_conditions\n",
    "            func: numpy function to be applied\n",
    "        Output:\n",
    "            logical mask for the given dataframe\n",
    "        '''\n",
    "    out = np.ones(len(list_of_conditions[0]),dtype=bool)\n",
    "    for i in range(len(list_of_conditions)):\n",
    "        out = func(out,list_of_conditions[i])\n",
    "    return out\n",
    "\n",
    "def interpIntervals(df,interp_cols,group_cols=['Well','Year'],dept_col='DEPT',interval=.5):\n",
    "    '''\n",
    "    Interpolates numerical values to a specified resolution (interval) \n",
    "    Meant for use with depth-registered well data\n",
    "        Input:\n",
    "            df: DataFrame\n",
    "            interp_cols: list\n",
    "            group_cols: list\n",
    "            dept_col: str\n",
    "            interval: numeric\n",
    "        Output:\n",
    "            DataFrame with interpolated rows\n",
    "    '''\n",
    "    frames = []\n",
    "    for key,group in df.groupby(by=group_cols):\n",
    "\n",
    "        all_cols = group.columns\n",
    "        dup_cols=[col for col in all_cols if (col not in (interp_cols+[dept_col]))]\n",
    "\n",
    "        #interpolation\n",
    "        x_eval = np.arange(group.loc[:,dept_col].values[0],group.loc[:,dept_col].values[-1]+interval,interval)\n",
    "        xp = group.loc[:,dept_col].values\n",
    "        y_eval={}\n",
    "        for col in interp_cols:\n",
    "            yp = group.loc[:,col].values\n",
    "            y_eval[col]=np.interp(x_eval,xp,yp)\n",
    "\n",
    "        #create new DF\n",
    "        df_out = pd.DataFrame(columns=all_cols)\n",
    "        df_out = df_out.append([df.loc[group.index[0],dup_cols]]*len(x_eval))\n",
    "        for col in interp_cols:\n",
    "            df_out.loc[:,col] = y_eval[col]\n",
    "        df_out.loc[:,dept_col] = x_eval\n",
    "\n",
    "        #concatenate frames\n",
    "        frames.append(df_out)\n",
    "    return pd.concat(frames).reset_index(drop=True)\n",
    "\n",
    "def concat_dfs(dfs):\n",
    "    dfs = [sc_df_interp,df2]\n",
    "    new_dfs = []\n",
    "    maxind= 0\n",
    "\n",
    "    for df in dfs:\n",
    "        df_index = df.index.values + maxind + 1\n",
    "        maxind = np.max(df_index)\n",
    "        df.loc[:,'new_index'] = df_index\n",
    "        df.set_index('new_index',inplace=True)\n",
    "        new_dfs.append(df)\n",
    "    return pd.concat(new_dfs,axis=0,sort=True)\n",
    "\n",
    "def update_df2():\n",
    "    return df.reset_index().rename(columns={\"level_0\": \"Well\"})\n",
    "\n",
    "def update_FBS(df,TDS_col):\n",
    "    FBS = np.zeros(len(df))\n",
    "    FBS[df.loc[:,TDS_col].isna()] = np.nan\n",
    "    FBS[df.loc[:,TDS_col] <= 3000] = 1\n",
    "    FBS[np.logical_and(df.loc[:,TDS_col] > 3000,df.loc[:,TDS_col] < 10000)] = 2\n",
    "    FBS[df.loc[:,TDS_col] >= 10000] = 3\n",
    "    return df.assign(FBS=FBS)\n",
    "\n",
    "def m2ft(df,colname,newcolname=None):\n",
    "    if newcolname is None:\n",
    "        newcolname = colname + 'ft'\n",
    "    df[newcolname] = df[colname]/.3048\n",
    "    return\n",
    "\n",
    "def interval2point(pointdf,intervaldf,testcol,topcol='topft',botcol='botft'):\n",
    "    df_list = []\n",
    "    for d in pointdf.index:\n",
    "        v=intervaldf[((d>=intervaldf[topcol]) & (d<intervaldf[botcol]))][testcol]\n",
    "        if len(v)==1:\n",
    "            df_list.append(v.values[0])\n",
    "        elif len(v)>1:\n",
    "            print(v)\n",
    "            raise Exception('multiple values in this interval ??')\n",
    "        else:\n",
    "            df_list.append(np.nan)\n",
    "    return df_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = False\n",
    "clip_bad_data=True\n",
    "\n",
    "if not recompute:\n",
    "    df =  pd.read_pickle(lasdir.joinpath('allMWs'))\n",
    "    df_ind =  pd.read_pickle(lasdir.joinpath('allMWs_ind'))\n",
    "    MWnames = df.index.levels[0].values\n",
    "else:\n",
    "    f_MWm = glob.glob(lasdir.joinpath('*[1-9]m.las').as_posix())\n",
    "    for f in f_MWm:\n",
    "        lasobj = lasio.read(f)\n",
    "        lasexpt = lasio.LASFile()\n",
    "\n",
    "        for c in lasobj.curves:\n",
    "            if c.mnemonic=='DEPT':\n",
    "                continue\n",
    "            lasexpt.insert_curve_item(0,c)\n",
    "        #make sure DEPT is the first curve for aesthetics\n",
    "        d = lasobj.get_curve('DEPT')\n",
    "        d_mode = mode(np.diff(np.round(d.data/.3048,decimals=2))).mode[0]\n",
    "        if d_mode==0.5:\n",
    "            lasexpt.insert_curve(0,'DEPT',myround(d.data/.3048,base=.5),unit='F')\n",
    "            lasexpt.write(f[:-5]+'_all.las')\n",
    "        else:\n",
    "            raise Exception('Needs to be .5 feet')\n",
    "\n",
    "    ########## Create list of DataFrames\n",
    "    f_MWall = glob.glob(lasdir.joinpath('*_all.las').as_posix())\n",
    "    f_MWall = sorted(f_MWall,key=os.path.basename)\n",
    "    MWnames = [Path(f).stem[:-4] for f in f_MWall]\n",
    "\n",
    "    frames = []\n",
    "    for f in f_MWall:\n",
    "        las = lasio.read(f)\n",
    "        #Convert to DF and mask for plots\n",
    "        df_temp = las.df()\n",
    "        frames.append(df_temp)\n",
    "\n",
    "    ######### Meters to feet for lith and screen\n",
    "    def m2ft(df,colname,newcolname=None):\n",
    "        if newcolname is None:\n",
    "            newcolname = colname + 'ft'\n",
    "        df[newcolname] = df[colname]/.3048\n",
    "        return\n",
    "\n",
    "    mwcollar = pd.read_excel(auxdir.joinpath('MPWSP_Collar.xlsx'))\n",
    "    mwlith= pd.read_excel(auxdir.joinpath('Lith_MPWSP.xlsx'))\n",
    "    mwtds= pd.read_excel(auxdir.joinpath('TDS_Baseline_MPWSP.xlsx'),index_col=0)\n",
    "    mwscreen = pd.read_excel(auxdir.joinpath('MPWSP_Screen.xlsx'),index_col=0)\n",
    "    mwchem = pd.read_excel(auxdir.joinpath('WQ_Baseline_MPWSP.xlsx'),index_col=0)\n",
    "    wellids = np.unique(mwlith['WellID'])\n",
    "\n",
    "\n",
    "    m2ft(mwlith,'Top_m','topft')\n",
    "    m2ft(mwlith,'Bottom_m','botft')\n",
    "    m2ft(mwscreen,'Screen_Top','topft')\n",
    "    m2ft(mwscreen,'Screen_Bottom','botft')\n",
    "    \n",
    "    for i,frame in enumerate(frames):\n",
    "        nam = MWnames[i]\n",
    "        print('processing',nam)\n",
    "        TDS1_list = np.nan*np.zeros(len(frame))\n",
    "        TDS2_list = np.nan*np.zeros(len(frame))\n",
    "        EC1_list = np.nan*np.zeros(len(frame))\n",
    "        EC2_list = np.nan*np.zeros(len(frame))\n",
    "        EC1f_list = np.nan*np.zeros(len(frame))\n",
    "        EC2f_list = np.nan*np.zeros(len(frame))\n",
    "        TMPf1_list = np.nan*np.zeros(len(frame))\n",
    "        TMPf2_list = np.nan*np.zeros(len(frame))\n",
    "\n",
    "        #Assign X and Y\n",
    "        frame = frame.assign(X=mwcollar.loc[mwcollar.Well==nam,'X'].values[0]*np.ones(len(frame)))\n",
    "        frame = frame.assign(Y=mwcollar.loc[mwcollar.Well==nam,'Y'].values[0]*np.ones(len(frame)))\n",
    "        frame = frame.assign(Region=list(mwcollar.loc[mwcollar.Well==nam,'Region'].values)*len(frame))\n",
    "\n",
    "        #Assign lith\n",
    "        lith_list = interval2point(frame,mwlith.loc[lambda df: df['WellID'] == nam]\n",
    "                   ,'Lith_Code_Orig',topcol='topft',botcol='botft')\n",
    "        frame = frame.assign(lith=lith_list)\n",
    "\n",
    "        #Assign screen and aquifer name\n",
    "        screen_list = interval2point(frame,mwscreen.loc[lambda df: df.index == nam]\n",
    "                   ,'Alt_ID',topcol='topft',botcol='botft')\n",
    "        screen_len_list = interval2point(frame,mwscreen.loc[lambda df: df.index == nam]\n",
    "                   ,'Screen_Len_ft',topcol='topft',botcol='botft')\n",
    "        aq_list = interval2point(frame,mwscreen.loc[lambda df: df.index == nam]\n",
    "                   ,'TargetedAquifer',topcol='topft',botcol='botft')\n",
    "        aq_group_list = interval2point(frame,mwscreen.loc[lambda df: df.index == nam]\n",
    "                   ,'GroupedAquifer',topcol='topft',botcol='botft')\n",
    "\n",
    "        frame = frame.assign(screen=screen_list)\n",
    "        frame = frame.assign(screen_len=screen_len_list)\n",
    "        frame = frame.assign(Aquifer=aq_list)\n",
    "        frame = frame.assign(AquiferGroup=aq_group_list)\n",
    "\n",
    "        #Assign TDS measurements to each screen\n",
    "        for scrn in frame.screen.dropna().unique():\n",
    "            framebool = frame['screen']==scrn #entries in frame matching the well and screen\n",
    "            screenbool = np.logical_and(mwtds.index == nam,mwtds['WellScreen'] == scrn) #matching entries in mwtds\n",
    "            chembool = np.logical_and(mwchem.index == nam,mwchem['WellScreen'] == scrn)\n",
    "            nmeas = len(mwtds.loc[screenbool,'TDS(mg/L)'])\n",
    "            if nmeas==2:\n",
    "                TDS1_list[framebool] =mwtds.loc[screenbool,'TDS(mg/L)'].iloc[0]\n",
    "                TDS2_list[framebool] =mwtds.loc[screenbool,'TDS(mg/L)'].iloc[1]     \n",
    "                EC1_list[framebool] =mwchem.loc[chembool,'SPECIFIC CONDUCTANCE (E.C)'].iloc[0]\n",
    "                EC2_list[framebool] =mwchem.loc[chembool,'SPECIFIC CONDUCTANCE (E.C)'].iloc[1] \n",
    "                EC1f_list[framebool] =mwchem.loc[chembool,'SPECIFIC CONDUCTANCE (E.C) (FIELD)'].iloc[0]\n",
    "                EC2f_list[framebool] =mwchem.loc[chembool,'SPECIFIC CONDUCTANCE (E.C) (FIELD)'].iloc[1] \n",
    "                TMPf1_list[framebool] =mwchem.loc[chembool,'TEMPERATURE, (FIELD)'].iloc[0]\n",
    "                TMPf2_list[framebool] =mwchem.loc[chembool,'TEMPERATURE, (FIELD)'].iloc[1] \n",
    "            elif nmeas==1:\n",
    "                TDS1_list[framebool] =mwtds.loc[screenbool,'TDS(mg/L)'].iloc[0]\n",
    "                try:\n",
    "                    TMPf1_list[framebool] =mwchem.loc[chembool,'TEMPERATURE, (FIELD)'].iloc[0]\n",
    "                    EC1_list[framebool] =mwchem.loc[chembool,'SPECIFIC CONDUCTANCE (E.C)'].iloc[0]\n",
    "                    EC1f_list[framebool] =mwchem.loc[chembool,'SPECIFIC CONDUCTANCE (E.C) (FIELD)'].iloc[0]\n",
    "                except:\n",
    "                    print(\"No chem data found for well {} screen {}\".format(nam,scrn))\n",
    "            else:\n",
    "                print('Num of measurements:',nmeas)\n",
    "                raise Exception('Number of measurements not equal to 1 or 2')\n",
    "\n",
    "        frame = frame.assign(TDS1=TDS1_list)\n",
    "        frame = frame.assign(TDS2=TDS2_list)\n",
    "        frame = frame.assign(EC1=EC1_list)\n",
    "        frame = frame.assign(EC2=EC2_list)\n",
    "        frame = frame.assign(EC1f=EC1f_list)\n",
    "        frame = frame.assign(EC2f=EC2f_list)\n",
    "        frame = frame.assign(TMPf1=TMPf1_list)\n",
    "        frame = frame.assign(TMPf2=TMPf2_list)\n",
    "        frame[frame.loc[:,['TDS1','TDS2','EC1','EC2','EC1f','EC2f','TMPf1','TMPf2']]==0]=np.nan\n",
    "\n",
    "        #Assign to list\n",
    "        frames[i] = frame\n",
    "\n",
    "    ######### Join all frames together\n",
    "    df = pd.concat(frames, keys=MWnames, sort=False)\n",
    "\n",
    "\n",
    "    ######### Replace 'Gravelly/silty sand w/clay' with 'SC-SM'\n",
    "    df.loc[df.lith == 'Gravelly/silty sand w/clay','lith'] = 'SC-SM'\n",
    "\n",
    "    ######### Add FRESc\n",
    "    def degc2f(degc):\n",
    "        return (degc*9/5)+32\n",
    "    ref_temp= 77 #fahrenheit\n",
    "    fresc = df.loc[:,'FRES']*(df.loc[:,'TMP']+6.77)/(ref_temp + 6.77)\n",
    "    df=df.assign(FRESc = fresc);\n",
    "    ec_fresc = cond2rho(df.loc[:,'EC1f'])*(degc2f(df.loc[:,'TMPf1'])+6.77)/(ref_temp + 6.77)\n",
    "    df=df.assign(ec_fresc=ec_fresc)\n",
    "\n",
    "    ######### Add aquifer number\n",
    "    aqnum = -1*np.ones(len(df),dtype='Int32')\n",
    "    aq_names = df[df.Aquifer.notna()].Aquifer.unique()\n",
    "    aq_names.sort()\n",
    "    for i,aq in enumerate(aq_names):\n",
    "        aqnum[df.Aquifer == aq_names[i]] = i\n",
    "\n",
    "    df=df.assign(aqnum=aqnum)\n",
    "\n",
    "    \n",
    "    if clip_bad_data:\n",
    "        ######### Record intervals of bad data at top and bottom of borehole\n",
    "        topft = np.zeros(np.shape(MWnames))\n",
    "        botft = np.zeros(np.shape(MWnames))\n",
    "        data_rng = pd.DataFrame(np.r_[[MWnames,topft,botft]].T,columns=['Well','topft','botft'])\n",
    "        def assign_top_bot(df,nam,top,bot):\n",
    "            df.loc[df['Well']==nam,['topft','botft']] = (top,bot)\n",
    "        assign_top_bot(data_rng,'MW-1D',100 ,330)\n",
    "        assign_top_bot(data_rng,'MW-4D',0   ,331.0)\n",
    "        assign_top_bot(data_rng,'MW-5D',75   ,426.5)\n",
    "        assign_top_bot(data_rng,'MW-6D',40   ,400)\n",
    "        assign_top_bot(data_rng,'MW-7D',70  ,345)\n",
    "        assign_top_bot(data_rng,'MW-8D',30   ,350)\n",
    "        assign_top_bot(data_rng,'MW-9D',5   ,392)\n",
    "#         #Do some manual clipping of bad data at the top and bottom of tracks\n",
    "#         top,bot =data_rng.loc[data_rng['Well']==nam,['topft','botft']].values[0]\n",
    "#         frame.loc[frame.index<top,['FRES','RILD']] = np.nan\n",
    "#         frame.loc[frame.index>bot,['FRES','RILD']] = np.nan   \n",
    "\n",
    "    \n",
    "    ######### Save DF\n",
    "    df_ind = pd.DataFrame(df.index.tolist(), columns=['Well','DEPT'])\n",
    "\n",
    "    df.to_pickle(lasdir.joinpath('allMWs'))\n",
    "    df_ind.to_pickle(lasdir.joinpath('allMWs_ind'))\n",
    "    print('Done reprocessing from raw data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Dune_Sand', '180-FTE', '180/400-Foot Aquitard', '400-Foot',\n",
       "       'A_Perched', '180-Foot', 'A', '180-Foot_Lower'], dtype=object)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Aquifer.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Soquel Creek data and interpolate to .5 feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianpg/anaconda/envs/SWIenv/lib/python3.6/site-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reprocessing from raw data!\n"
     ]
    }
   ],
   "source": [
    "sc_df = pd.read_excel(auxdir.joinpath('SoquelCreek.xlsx'))\n",
    "sc_df_interp = interpIntervals(sc_df,interp_cols = ['RILD'],group_cols=['Well','Year'],dept_col='DEPT',interval=.5)\n",
    "sc_df_interp.to_pickle(lasdir.joinpath('SoquelCreek'))\n",
    "\n",
    "\n",
    "df2 = update_df2()\n",
    "df2.to_pickle(lasdir.joinpath('allMWs_df2'))\n",
    "\n",
    "# df = concat_dfs((df2,sc_df_interp.set_index(['Well','DEPT'])))\n",
    "df = pd.concat((df,sc_df_interp.set_index(['Well','DEPT'])),sort=False)\n",
    "\n",
    "#Add Rw_est\n",
    "Rw_est = np.zeros(len(df))\n",
    "Rw_est[~df.TDS1.isna()] = tds2rho_est(df[~df.TDS1.isna()].TDS1)\n",
    "Rw_est[~df.EC1f.isna()]=cond2rho(df[~df.EC1f.isna()].EC1f)\n",
    "Rw_est[df.TDS1.isna()]=np.nan\n",
    "df = df.assign(Rw_est=Rw_est)\n",
    "\n",
    "df_ind = pd.DataFrame(df.index.tolist(), columns=['Well','DEPT'])\n",
    "df.to_pickle(lasdir.joinpath('allMWs_SC'))\n",
    "df_ind.to_pickle(lasdir.joinpath('allMWs_SC_ind'))\n",
    "print('Done reprocessing from raw data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SWIenv]",
   "language": "python",
   "name": "conda-env-SWIenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
